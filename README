## 通过FFMPEG 实现音频文件的播放  ，变调，变速。

-4.13 基本ui搭建，实现开始，播放，暂停，停止。

      引入ffmpeg库，avcodec 解码库
                   avformat todo
                   avutil todo
                   avswscale todo 缩放

-4.13 引入FFMPEG so 库 和 头文件


-4.13  构建 播放 暂停 开启 停止 功能。（TODO 该功能只是定义了 暂未实现）

-4.14 （TODO 还未实现）
      增加JavaBridge.cpp 用来回调给Java方法，以及添加队列操作(BufferQueue.cpp 典型的生产者消费者模型)，用来缓存解码过程的数据，达到边解码边播放的效果
      现在当前的播放状态PlayStatus.cpp

-4.15 队列代码初步完善


    ```
         注意AVFormatContext中包含了多个流信息，每个流信息在AVMediaType中去匹配，比如音频AUDIO 视频VIDEO ，所以在这里比对角标是很有必要的。
         Question：如何知道av_read_frame(avFormatContext,avPacket)读取的packet是属于哪个流的数据包呢，
         Answer: 我们通过在AVFormatContext,遍历所有的流信息，然后根据AVMediaType匹配是否为对应的流，然后记下各自流的角标，因此在从AVFormatContext读取的时候就可以对应的上了。
     ```
-4.15   修复null指针问题 播放功能完善，队列操作完善；（To 4.14）

-4.15  增加暂停 恢复播放操作


-4.15 增加播放时长和总时长显示

       时间的计算（针对的是AVPacket 转换为 AVFrame 此时播放的数据是Avframe 因此从该处进行时间的计算）

       总时长：   AvFormatContext ->duration

       当前时长： AVFrame 中计算时间 int now_time = avFrame->pts * av_q2d(timeBase);

       播放时长： 转换为 --- 当前读取的buffer / 当前buffer的采样率*声道数*位宽 = n个 单位时间

                 累加 得到播放时长



-4.15 增加停止功能，并且释放播放器 内存等


-4.15 增加播放出错回调

-4.15 增加播放进度条功能

      读取packet的时候保证队列中有值，不然在解码过程中，直接就退出了，

      TODO seek 功能和 start 功能 反复来回切换，导致崩溃，原因是 prepare 方法调用一次，why。


-4.16 增加手动自动播放下一首功能

      播放下一首主要是调用stop 回收资源之后，回调函数到java层 java重新设置url。然后走prepare 这些流程，

-4.16 声音控制
      注意的是在使用声音接口的时候，需要将SL_IID_VOLUME注册到引擎创建AudioPlayer中去 不然无法生效

      const SLInterfaceId ids[2] ={SL_IID_BUFFERQUEUE,SL_IID_VOLUME}

      CreateAudioPlayer(...., ids,)

-4.16 声道切换

        初始化：
        (*pcmPlayerObject)->GetInterface(
        				pcmPlayerObject,
        				SL_IID_MUTESOLO,
        				&pcmPlayPlayerMuteSolo);
        设置声道：
        (*pcmPlayPlayerMuteSolo)->SetChannelMute(
        				pcmPlayPlayerMuteSolo,
        				1,  //0右声道1左声道
        				false //声道是否开启
        				);




-4.18 记录lame的编译 通过采用CMake方式编译，导入源码 编写make脚本，但是一定是要切记的是
      由于lame库是c程序编写的，里面有一个STD_HEADERS的宏定义 需要在build.gradle中的cFlags 而不是默认生成的
      cppFlags 定义"-DSTD_HEADERS" 相当于是告诉编译器 我们定义一个STD_HEADERS的宏定义，不然编译过程中会报错。

      将lame源码打包成so库，直接引入到nativelib中使用，使用方式和ffmpeg中的so库引入一样，
      add_library(lame SHARED IMPORTED)
      set_target_properties(
               lame
                PROPERTIES PROPERTIES_LOCATION

                 路径）

-4.20 梳理soundTouch变速变调的流程，
      详细查看AudioController.cpp中的getSoundTouchData方法


-4.20 实现边播放边录制功能
    关于AAC头信息 参考https://blog.csdn.net/jay100500/article/details/52955232


-4.21 实现边播放边录制功能 TODO 对于采样率过大的会导致崩溃 dev15_fix_big_pcm_data 进行pack分包处理防止崩溃现象。
      通过MediaCodec 完成录制功能，
      通过mediaCodec创建一个AAC编码器encoder 完成相关的配置，比如配置最大输入媒体格式（KEY_MAX_INPUT_SIZE《很重要，对于如果超过这个值就需要进行分包操作，不然会内存溢出》） 采样率（KEY_BIT_RATE)等
      然后通过这个encoder调用dequeueInputBuffer()方法拿到对应的inputbuffer缓冲byte数组的下标，通过该下标获取对应的输入缓冲区，调用queueInputQueue将该对应的缓冲区下标的pcm数据加入到缓冲区中，
      通过encoder调用dequeueOutputBuffer获取输出缓冲区角标，通过该角标获取输出缓冲区，然后调用输出缓冲区ByteBuffer的get方法将数据写入到定义的输出数组中。
      最后调用releaseOutBuffer进行资源释放角标，因为该角标对应的缓冲区已经写入到输出数组中去了，因此队列中不需要该缓冲区了。


-4.21 解决了pcm大数据包引起的录制崩溃问题
      解决手段，通过将pcm数据加入到队列中，然后通过生产者消费者模型，在加入数据到队列的同时，通过回调中处理取出队列中的数据，然后对数据进行分包处理，
      如果当前取出的数据帧的大小小于预设定的值则不需要进行分包处理，直接回调给java层，如果大于，则需要通过数据包的取整和取余 将大数据块分为若干个
      预设定值的正常范围的数据块进行回调处理，接下来的小于预设定值的数据块也通过回调余下来的数据给java层。